{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "665cd21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\EmiliaGachowetz-Gepp\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f510833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d772449",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69e847d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51526</th>\n",
       "      <th>51527</th>\n",
       "      <th>51528</th>\n",
       "      <th>51529</th>\n",
       "      <th>51530</th>\n",
       "      <th>51531</th>\n",
       "      <th>51532</th>\n",
       "      <th>51533</th>\n",
       "      <th>51534</th>\n",
       "      <th>51535</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255</td>\n",
       "      <td>254</td>\n",
       "      <td>249</td>\n",
       "      <td>242</td>\n",
       "      <td>243</td>\n",
       "      <td>253</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>250</td>\n",
       "      <td>208</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>1075391489.jpg</td>\n",
       "      <td>Nbc</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1075391489.jpg</td>\n",
       "      <td>Nbc</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>254</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>1075391489.jpg</td>\n",
       "      <td>Nbc</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>98</td>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>94</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108232382.jpg</td>\n",
       "      <td>Citroen</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>29</td>\n",
       "      <td>426</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>98</td>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>94</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108232382.jpg</td>\n",
       "      <td>Citroen</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>29</td>\n",
       "      <td>426</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51536 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  0     1     2     3     4     5     6     7     8     9      ... 51526  \\\n",
       "0   255   254   249   242   243   253   255   255   250   208  ...    24   \n",
       "1     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2   252   255   255   254   255   255   251   251   255   255  ...   255   \n",
       "3    98    97    97    98   100    98    95    93    94    96  ...     0   \n",
       "4    98    97    97    98   100    98    95    93    94    96  ...     0   \n",
       "\n",
       "  51527 51528           51529    51530 51531 51532 51533 51534 51535  \n",
       "0    25    25  1075391489.jpg      Nbc     6     2     4    77    58  \n",
       "1     0     0  1075391489.jpg      Nbc     6     2     4    77    58  \n",
       "2   255   255  1075391489.jpg      Nbc     6     2     4    77    58  \n",
       "3     0     0   108232382.jpg  Citroen     3    75    29   426   305  \n",
       "4     0     0   108232382.jpg  Citroen     4    75    29   426   305  \n",
       "\n",
       "[5 rows x 51536 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Re-Load the dataset\n",
    "loaded_data = np.load(\"my_dataset_aug_full.npz\", allow_pickle=True)\n",
    "\n",
    "# Access images and labels\n",
    "loaded_images = loaded_data['images']\n",
    "\n",
    "# Now you can use loaded_images and loaded_labels in your code\n",
    "image_df=pd.DataFrame(loaded_images)\n",
    "image_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5919bb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       6\n",
       "1       6\n",
       "2       6\n",
       "3       3\n",
       "4       4\n",
       "       ..\n",
       "9902    5\n",
       "9903    6\n",
       "9904    4\n",
       "9905    5\n",
       "9906    6\n",
       "Name: 51531, Length: 9907, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split it into features and labels\n",
    "features = image_df.iloc[:, :51529]\n",
    "labels = image_df.iloc[:, 51530]\n",
    "labels_coded=image_df.iloc[:,51531]\n",
    "labels_coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26cf3722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (7925, 51529)\n",
      "X_test shape: (1982, 51529)\n",
      "y_train shape: (7925,)\n",
      "y_test shape: (1982,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels_coded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting splits\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4679bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_pic = X_train.iloc[0]\n",
    "one_pic_array = one_pic.values.astype(float)  # Convert to float\n",
    "one_pic_image = one_pic_array.reshape((227, 227))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(one_pic_image)\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bc806a",
   "metadata": {},
   "source": [
    "The data must be preprocessed before training the network. When inspecting one image in the training set, it can be observed that the pixel values fall in the range of 0 to 255.\n",
    "These values can be scaled to a range of 0 to 1 before feeding them to the neural network model. To do so, divide the values by 255. It's important that the training set and the testing set be preprocessed in the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ae15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train/255.0\n",
    "X_test=X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a60cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to verify whether it worked: plot\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[y_train[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df468d38",
   "metadata": {},
   "source": [
    "Building the neural network requires configuring the layers of the model, then compiling the model.\n",
    "\n",
    "Set up the layers\n",
    "The basic building block of a neural network is the layer. Layers extract representations from the data fed into them. Hopefully, these representations are meaningful for the problem at hand.\n",
    "\n",
    "Most of deep learning consists of chaining together simple layers. Most layers, such as tf.keras.layers.Dense, have parameters that are learned during training.\n",
    "\n",
    "The first layer in this network, tf.keras.layers.Flatten, transforms the format of the images from a two-dimensional array (of 227 by 227 pixels) to a one-dimensional array (of 227 * 227 = 51528 pixels). Think of this layer as unstacking rows of pixels in the image and lining them up. This layer has no parameters to learn; it only reformats the data. --< true???\n",
    "\n",
    "After the pixels are flattened, the network consists of a sequence of two tf.keras.layers.Dense layers. These are densely connected, or fully connected, neural layers. The first Dense layer has 128 nodes (or neurons). The second (and last) layer returns a logits array with length of 27. Each node contains a score that indicates the current image belongs to one of the 27 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95ed8ad",
   "metadata": {},
   "source": [
    "## MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1ef1f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\EmiliaGachowetz-Gepp\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(227,227)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(27)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3867c992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\EmiliaGachowetz-Gepp\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805d6351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To start training, call the model.fit methodâ€”so called because it \"fits\" the model to the training data:\n",
    "model_1.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd51fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next, compare how the model performs on the test dataset:\n",
    "test_loss, test_acc = model_1.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b785c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "probability_model = tf.keras.Sequential([model_1, \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "\n",
    "predictions = probability_model.predict(X_test)\n",
    "print(predictions[0])\n",
    "#A prediction is an array of 10 numbers. They represent the model's \"confidence\" that the image corresponds to each of the 27 different logos.\n",
    "#You can see which label has the highest confidence value by calling:\n",
    "print(f'most probable logo is',np.argmax(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ac3db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model is most confident that this image is XX\n",
    "#Examining the test label shows that this classification is correct?False?:\n",
    "\n",
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98468e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/keras/classification\n",
    "#https://www.tensorflow.org/tutorials/images/cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca2a21",
   "metadata": {},
   "source": [
    "## 2ND MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a128bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",

model_2=keras.models.Sequential([
    keras.layers.Conv2D(filters=128, kernel_size=(5,5), activation='relu', input_shape=(227,227,3)),
    keras.layers.Conv2D(filters=256, kernel_size=(5,5), activation='relu', padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.Conv2D(filters=256, kernel_size=(5,5), activation='relu', padding="same"),
    keras.layers.MaxPool2D(pool_size=(2,2)),
    keras.layers.Conv2D(filters=256, kernel_size=(5,5), activation='relu', padding="same"),
    keras.layers.Conv2D(filters=256, kernel_size=(5,5), activation='relu', padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.MaxPool2D(pool_size=(2,2)),
    keras.layers.Conv2D(filters=256, kernel_size=(5,5), activation='relu', padding="same"),
    keras.layers.Conv2D(filters=256, kernel_size=(5,5), activation='relu', padding="same"),
    keras.layers.Conv2D(filters=256, kernel_size=(5,5), activation='relu', padding="same"),
    keras.layers.MaxPool2D(pool_size=(2,2)),
    keras.layers.Flatten(),
    keras.layers.Dense(512,activation='relu'),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(256,activation='relu'),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(27,activation='softmax')  
    
    
])
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6231c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a513530",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_2(X_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9617e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using `tf.nn.softmax` function converts these logits to *probabilities* for each class: \n",
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a12dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a loss function for training using `losses.SparseCategoricalCrossentropy`:\n",
    "#This loss is equal to the negative log probability of the true class: \n",
    "#The loss is zero if the model is sure of the correct class.\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5acd957",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9919f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before training, configuring and compiling the model\n",
    "#Setting the optimizer class to adam, the loss to the loss_fn function defined earlier\n",
    "\n",
    "model_2.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "#or as before but with sgd: model_2.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             #optimizer=\"sgd\",\n",
    "            # metrics=[\"accuracy\"]) we use sparse... bc sparse labels and classes are exclusive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10305c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and evaluation\n",
    "history=model_2.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test))\n",
    "\n",
    "#or Model.evaluate` method checks the model's performance, usually on a validation set and test set\n",
    "#model_2.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00da18f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model to return a probability, you can wrap the trained model, and attach the softmax to it:\n",
    "probability_model = tf.keras.Sequential([model_2, tf.keras.layers.Softmax()])\n",
    "probability_model(X_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922d58cb",
   "metadata": {},
   "source": [
    "## TRYOUTS WTH SUBSET OF LENGTH 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99955064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try-outs with smaller subsets:\n",
    "X_train_subset = X_train[:100]\n",
    "y_train_subset = y_train[:100]\n",
    "X_test_subset = X_test[:100]\n",
    "y_test_subset = y_test[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66bb412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subset=X_train_subset/255.0\n",
    "X_test_subset=X_test_subset/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff0fd339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "        [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "        [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "        ...,\n",
       "        [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "        [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "        [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0]],\n",
       "\n",
       "       [[0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "        [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "        [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "        ...,\n",
       "        [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "        [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "        [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0]],\n",
       "\n",
       "       [[0.03137254901960784, 0.03137254901960784, 0.023529411764705882,\n",
       "         ..., 0.06274509803921569, 0.06274509803921569,\n",
       "         0.12156862745098039],\n",
       "        [0.03529411764705882, 0.03529411764705882, 0.027450980392156862,\n",
       "         ..., 0.058823529411764705, 0.12549019607843137,\n",
       "         0.10588235294117647],\n",
       "        [0.0392156862745098, 0.0392156862745098, 0.03137254901960784,\n",
       "         ..., 0.11764705882352941, 0.1450980392156863,\n",
       "         0.043137254901960784],\n",
       "        ...,\n",
       "        [0.796078431372549, 0.6901960784313725, 0.7137254901960784, ...,\n",
       "         0.996078431372549, 0.996078431372549, 0.996078431372549],\n",
       "        [0.5294117647058824, 0.6313725490196078, 0.803921568627451, ...,\n",
       "         0.9921568627450981, 0.9921568627450981, 0.9921568627450981],\n",
       "        [0.9921568627450981, 0.9450980392156862, 0.996078431372549, ...,\n",
       "         1.0, 1.0, 1.0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.13725490196078433, 0.13725490196078433, 0.13725490196078433,\n",
       "         ..., 0.3058823529411765, 0.3058823529411765,\n",
       "         0.2980392156862745],\n",
       "        [0.1450980392156863, 0.1450980392156863, 0.1450980392156863,\n",
       "         ..., 0.30196078431372547, 0.30980392156862746,\n",
       "         0.30980392156862746],\n",
       "        [0.1450980392156863, 0.1450980392156863, 0.1450980392156863,\n",
       "         ..., 0.28627450980392155, 0.3137254901960784,\n",
       "         0.33725490196078434],\n",
       "        ...,\n",
       "        [0.09019607843137255, 0.09411764705882353, 0.09411764705882353,\n",
       "         ..., 0.6470588235294118, 0.615686274509804, 0.5372549019607843],\n",
       "        [0.09019607843137255, 0.09411764705882353, 0.10196078431372549,\n",
       "         ..., 0.7019607843137254, 0.6274509803921569,\n",
       "         0.48627450980392156],\n",
       "        [0.09411764705882353, 0.09803921568627451, 0.10588235294117647,\n",
       "         ..., 0.6705882352941176, 0.6235294117647059,\n",
       "         0.5568627450980392]],\n",
       "\n",
       "       [[0.10196078431372549, 0.047058823529411764, 0.06274509803921569,\n",
       "         ..., 1.0, 1.0, 1.0],\n",
       "        [0.06274509803921569, 0.043137254901960784,\n",
       "         0.050980392156862744, ..., 1.0, 1.0, 1.0],\n",
       "        [0.06274509803921569, 0.06666666666666667, 0.047058823529411764,\n",
       "         ..., 1.0, 1.0, 1.0],\n",
       "        ...,\n",
       "        [0.00784313725490196, 0.00784313725490196, 0.00392156862745098,\n",
       "         ..., 0.5019607843137255, 0.44313725490196076,\n",
       "         0.43137254901960786],\n",
       "        [0.011764705882352941, 0.011764705882352941,\n",
       "         0.00784313725490196, ..., 0.4980392156862745,\n",
       "         0.4549019607843137, 0.44313725490196076],\n",
       "        [0.00392156862745098, 0.011764705882352941, 0.01568627450980392,\n",
       "         ..., 0.4745098039215686, 0.47843137254901963,\n",
       "         0.4392156862745098]],\n",
       "\n",
       "       [[0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "        [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "        [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "        ...,\n",
       "        [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "        [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "        [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0]]], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_subset_array = X_train_subset.to_numpy()  # Convert DataFrame to NumPy array\n",
    "\n",
    "# Reshape the array\n",
    "X_train_reshaped = X_train_subset_array.reshape(100,227, 227)\n",
    "X_train_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07eac6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_subset.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4108a0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\EmiliaGachowetz-Gepp\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\EmiliaGachowetz-Gepp\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "4/4 [==============================] - 2s 95ms/step - loss: 22.9530 - accuracy: 0.1500\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 51.5131 - accuracy: 0.1600\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 32.4151 - accuracy: 0.2600\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 13.3595 - accuracy: 0.1800\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 7.0376 - accuracy: 0.2900\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 8.5553 - accuracy: 0.3400\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 8.9314 - accuracy: 0.3800\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 7.6846 - accuracy: 0.2900\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 4.8503 - accuracy: 0.3500\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 4.2785 - accuracy: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1cf2d35fc90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert X_train_reshaped to float32\n",
    "X_train_reshaped = np.array(X_train_reshaped, dtype=np.float32)\n",
    "y_train_subset=np.array(y_train_subset, dtype=np.float32)\n",
    "\n",
    "model_1.fit(X_train_reshaped, y_train_subset, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51e9f91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_subset_array = X_test_subset.to_numpy()\n",
    "X_test_reshaped = X_test_subset_array.reshape(100,227, 227)\n",
    "X_test_reshaped = np.array(X_test_reshaped, dtype=np.float32)\n",
    "y_test_subset=np.array(y_test_subset, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66ffea34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 7.6268 - accuracy: 0.1500 - 296ms/epoch - 74ms/step\n",
      "\n",
      "Test accuracy: 0.15000000596046448\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_1.evaluate(X_test_reshaped,  y_test_subset, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca121640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n",
      "[0.0000000e+00 4.2946979e-11 5.3374151e-06 1.3950535e-07 8.8336325e-01\n",
      " 1.1122622e-01 5.4050791e-03 0.0000000e+00 0.0000000e+00 1.0517528e-30\n",
      " 0.0000000e+00 0.0000000e+00 4.4518637e-35 0.0000000e+00 1.0067840e-29\n",
      " 6.1832690e-22 3.7465659e-38 0.0000000e+00 3.3313345e-32 5.0300713e-29\n",
      " 1.8520107e-17 7.6610229e-37 4.1191497e-22 1.8820728e-32 1.9198959e-25\n",
      " 4.2216096e-16 0.0000000e+00]\n",
      "most probable logo is 4\n"
     ]
    }
   ],
   "source": [
    "#predictions\n",
    "probability_model = tf.keras.Sequential([model_1, \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "\n",
    "predictions = probability_model.predict(X_test_reshaped)\n",
    "print(predictions[0])\n",
    "#A prediction is an array of 10 numbers. They represent the model's \"confidence\" that the image corresponds to each of the 27 different logos.\n",
    "#You can see which label has the highest confidence value by calling:\n",
    "print(f'most probable logo is',np.argmax(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1ab332d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the model is most confident that this image is 4\n",
    "#Examining the test label shows that this classification is correct?False?:\n",
    "\n",
    "y_test_subset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d8ebc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

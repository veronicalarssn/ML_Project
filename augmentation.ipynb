{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b72e2d5",
   "metadata": {},
   "source": [
    "data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d91eb48",
   "metadata": {},
   "source": [
    "Data augmentation is a technique used in machine learning and deep learning to artificially increase the size of a training dataset by applying various transformations to the existing data. The goal is to enhance the model's generalization ability, robustness, and performance by exposing it to a more diverse set of examples during training. This technique is particularly useful when the available dataset is limited.\n",
    "\n",
    "Common data augmentation techniques include:\n",
    "\n",
    "1. **Rotation:** Rotating images by a certain degree.\n",
    "2. **Flip:** Flipping images horizontally or vertically.\n",
    "3. **Zoom:** Zooming in or out of images.\n",
    "4. **Translation:** Shifting images horizontally or vertically.\n",
    "5. **Shear:** Applying a shearing transformation to images.\n",
    "6. **Brightness and Contrast Adjustment:** Changing the brightness and contrast of images.\n",
    "7. **Noise Injection:** Adding random noise to images.\n",
    "8. **Color Jittering:** Adjusting the color values of images.\n",
    "\n",
    "For example, in image classification tasks, if you have a dataset of cat images, you can apply data augmentation to generate variations of the same images by rotating, flipping, zooming, or changing their colors. This way, the model sees different perspectives of the same data during training, which can help it become more robust to variations and improve its performance on new, unseen data.\n",
    "\n",
    "In deep learning frameworks and libraries, there are often built-in tools or functions for applying data augmentation during the training process. This allows practitioners to easily incorporate these transformations into their pipelines without manually creating augmented datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c04ef61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d92c2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "loaded_data = np.load(\"my_dataset.npz\")\n",
    "\n",
    "# Access images and labels\n",
    "loaded_images = loaded_data['images']\n",
    "\n",
    "# Now you can use loaded_images and loaded_labels in your code\n",
    "image_df=pd.DataFrame(loaded_images)\n",
    "image_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14c20e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Subset</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>144503924.jpg</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>234</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2451569770.jpg</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>1</td>\n",
       "      <td>242</td>\n",
       "      <td>208</td>\n",
       "      <td>413</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>390321909.jpg</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4761260517.jpg</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>122</td>\n",
       "      <td>358</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4763210295.jpg</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>63</td>\n",
       "      <td>130</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Image ID   Label  Subset   x1   y1   x2   y2\n",
       "0   144503924.jpg  Adidas       1   38   12  234  142\n",
       "1  2451569770.jpg  Adidas       1  242  208  413  331\n",
       "2   390321909.jpg  Adidas       1   13    5   89   60\n",
       "3  4761260517.jpg  Adidas       1   43  122  358  354\n",
       "4  4763210295.jpg  Adidas       1   83   63  130   93"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load info about the data set\n",
    "images_info=pd.read_csv(r\"C:\\Users\\EmiliaGachowetz-Gepp\\Documents\\New ML\\unzipped\\flickr_logos_27_dataset\\flickr_logos_27_dataset_training_set_annotation.txt\", sep='\\s+', header=None)\n",
    "\n",
    "#renaming the columns correspondingly:\n",
    "new_column_names = ['Image ID', 'Label', 'Subset', 'x1', 'y1','x2', 'y2']\n",
    "images_info.columns=new_column_names\n",
    "images_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d63b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array=image_df.values\n",
    "some_pic=image_array[0]\n",
    "some_pic_image=some_pic.reshape((227,227))\n",
    "\n",
    "coordinate_df=images.iloc[:, [0] + list(range(-4, 0))]\n",
    "coordinate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e250ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to augment pictures and save them in an extra folder\n",
    "def rotate_image(image, angle):\n",
    "    '''This function rotates the input image by a specifed angle and\n",
    "    returns a rotated image'''\n",
    "    rotated_image = image.rotate(angle)\n",
    "    return rotated_image\n",
    "\n",
    "def scale_image(image, scale_factor):\n",
    "    '''This function scales an input image by a scale factor'''\n",
    "\n",
    "    width, height = image.size\n",
    "    new_size = (int(width * scale_factor), int(height * scale_factor))\n",
    "    scaled_image = image.resize(new_size)\n",
    "    return scaled_image\n",
    "\n",
    "def crop_and_save_images(df, output_folder):\n",
    "    '''And finallz, this function crops the images and\n",
    "    then retursn the croppped, rotated and scaled images in a specified output folder'''\n",
    "\n",
    "    modified_df = pd.DataFrame(columns=['ImageID', 'Operation', 'FilePath'])\n",
    "\n",
    "    for index, row in images.iterrows():\n",
    "        image_id = row['Image ID']\n",
    "        x1, y1, x2, y2 = row['x1'], row['y1'], row['x2'], row['y2']\n",
    "        \n",
    "\n",
    "        # Open the image (assuming 'image_path' is the path to your image file)\n",
    "        image_path = f\"C:/Users/EmiliaGachowetz-Gepp/Documents/New ML/images/flickr_logos_27_dataset_images/{image_id}\"\n",
    "        original_image = Image.open(image_path)\n",
    "\n",
    "        # Rotate the image (example: 45 degrees)\n",
    "        rotated_image = rotate_image(original_image, angle=45)\n",
    "        rotated_image.save(f\"{output_folder}/image_{image_id}_rotated.jpg\")\n",
    "\n",
    "        # Scale the image (example: scale factor of 1.5)\n",
    "        scaled_image = scale_image(original_image, scale_factor=1.5)\n",
    "        scaled_image.save(f\"{output_folder}/image_{image_id}_scaled.jpg\")\n",
    "\n",
    "        # Crop the image and save (example: cropping a region)\n",
    "        cropped_image = original_image.crop((x1, y1, x2, y2))\n",
    "        cropped_image.save(f\"{output_folder}/image_{image_id}_cropped.jpg\")\n",
    "\n",
    "        # Update modified_df with unique identifiers and file paths\n",
    "        modified_df = modified_df._append({'ImageID': image_id, 'Operation': 'Rotated',\n",
    "                                          'FilePath': f\"{output_folder}/image_{image_id}_rotated.jpg\"}, ignore_index=True)\n",
    "        modified_df = modified_df._append({'ImageID': image_id, 'Operation': 'Scaled',\n",
    "                                          'FilePath': f\"{output_folder}/image_{image_id}_scaled.jpg\"}, ignore_index=True)\n",
    "        modified_df = modified_df._append({'ImageID': image_id, 'Operation': 'Cropped',\n",
    "                                          'FilePath': f\"{output_folder}/image_{image_id}_cropped.jpg\"}, ignore_index=True)\n",
    "\n",
    "    return modified_df\n",
    "\n",
    "# Example usage:\n",
    "output_folder = r\"C:\\Users\\EmiliaGachowetz-Gepp\\Documents\\New ML\\images_aug\"\n",
    "modified_df = crop_and_save_images(images, output_folder)\n",
    "print(modified_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34f22878",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m img_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img_resized\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Create a new DataFrame row with image data and file name\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m new_row \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([img_array], columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(img_array))])\n\u001b[0;32m     32\u001b[0m new_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m image_file  \u001b[38;5;66;03m# Add a new column for file name\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Append the new row to the image_df\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:790\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    781\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    782\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m nested_data_to_arrays(\n\u001b[0;32m    783\u001b[0m         \u001b[38;5;66;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;00m\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    788\u001b[0m         dtype,\n\u001b[0;32m    789\u001b[0m     )\n\u001b[1;32m--> 790\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    791\u001b[0m         arrays,\n\u001b[0;32m    792\u001b[0m         columns,\n\u001b[0;32m    793\u001b[0m         index,\n\u001b[0;32m    794\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    795\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    796\u001b[0m     )\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    798\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    799\u001b[0m         data,\n\u001b[0;32m    800\u001b[0m         index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    804\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    805\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;66;03m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m     arrays, refs \u001b[38;5;241m=\u001b[39m _homogenize(arrays, index, dtype)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# _homogenize ensures\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;66;03m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    126\u001b[0m \n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m     index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:607\u001b[0m, in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    604\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(val)\n\u001b[0;32m    605\u001b[0m     val \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mfast_multiget(val, oindex\u001b[38;5;241m.\u001b[39m_values, default\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m--> 607\u001b[0m val \u001b[38;5;241m=\u001b[39m sanitize_array(val, index, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    608\u001b[0m com\u001b[38;5;241m.\u001b[39mrequire_length_match(val, index)\n\u001b[0;32m    609\u001b[0m refs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\construction.py:544\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    541\u001b[0m     data \u001b[38;5;241m=\u001b[39m construct_1d_arraylike_from_scalar(data, \u001b[38;5;28mlen\u001b[39m(index), dtype)\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m--> 544\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ABCExtensionArray):\n\u001b[0;32m    545\u001b[0m     \u001b[38;5;66;03m# it is already ensured above this is not a PandasArray\u001b[39;00m\n\u001b[0;32m    546\u001b[0m     \u001b[38;5;66;03m# Until GH#49309 is fixed this check needs to come before the\u001b[39;00m\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;66;03m#  ExtensionDtype check\u001b[39;00m\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    549\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\generic.py:42\u001b[0m, in \u001b[0;36mcreate_pandas_abc_type.<locals>._instancecheck\u001b[1;34m(cls, inst)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(inst, attr, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_typ\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m comp\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# https://github.com/python/mypy/issues/1006\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# error: 'classmethod' used with a non-method\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_instancecheck\u001b[39m(\u001b[38;5;28mcls\u001b[39m, inst) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _check(inst) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inst, \u001b[38;5;28mtype\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_subclasscheck\u001b[39m(\u001b[38;5;28mcls\u001b[39m, inst) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# Raise instead of returning False\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# This is consistent with default __subclasscheck__ behavior\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Specify the path to your directory containing image files\n",
    "image_directory = r'C:\\Users\\EmiliaGachowetz-Gepp\\Documents\\New ML\\images_aug'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "image_files = [f for f in os.listdir(image_directory) if os.path.isfile(os.path.join(image_directory, f))]\n",
    "\n",
    "# Create an empty DataFrame\n",
    "image_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through image files and append to the DataFrame\n",
    "for index, image_file in enumerate(image_files):\n",
    "    try:\n",
    "        # Construct the full path to the image file\n",
    "        image_path = os.path.join(image_directory, image_file)\n",
    "\n",
    "        # Open the image using Pillow (PIL)\n",
    "        img = Image.open(image_path)\n",
    "\n",
    "        # Resize the image to 227x227 pixels using LANCZOS resampling filter\n",
    "        img_resized = img.resize((227, 227), Image.LANCZOS)\n",
    "\n",
    "        # Convert the resized image to a 1D NumPy array (flatten the image)\n",
    "        img_array = np.array(img_resized.convert('L')).flatten()\n",
    "\n",
    "        # Create a new DataFrame row with image data and file name\n",
    "        new_row = pd.DataFrame([img_array], columns=[f'pixel_{i}' for i in range(len(img_array))])\n",
    "        new_row['file_name'] = image_file  # Add a new column for file name\n",
    "\n",
    "        # Append the new row to the image_df\n",
    "        image_df = pd.concat([image_df, new_row], ignore_index=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle errors (e.g., if the image cannot be processed)\n",
    "        print(f\"Error processing image at index {index}: {e}\")\n",
    "\n",
    "# Display the new DataFrame containing image data and file names\n",
    "print(image_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78c63052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset using NumPy's .npz format\n",
    "np.savez(\"my_dataset_aug.npz\", images=image_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eb0cd05",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'file_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#now we need to give the augmented images their labels\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m image_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactual ID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m image_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.jpg)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(image_df, images_info, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactual ID\u001b[39m\u001b[38;5;124m'\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage ID\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m merged_df\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:349\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'file_name'"
     ]
    }
   ],
   "source": [
    "#now we need to give the augmented images their labels\n",
    "image_df['actual ID'] = image_df['file_name'].str.extract(r'(\\d+\\.jpg)')\n",
    "merged_df = pd.merge(image_df, images_info, left_on='actual ID', right_on='Image ID', how='inner')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f06c5307",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m images_full \u001b[38;5;241m=\u001b[39m merged_df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactual ID\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m images_full\n",
      "\u001b[1;31mNameError\u001b[0m: name 'merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "images_full = merged_df.drop(['file_name', 'actual ID'], axis=1)\n",
    "images_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ad63b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset using NumPy's .npz format\n",
    "np.savez(\"my_dataset_aug_full.npz\", images=image_full)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

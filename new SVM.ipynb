{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eab460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D, Dense, BatchNormalization, AveragePooling2D, Flatten\n",
    "from sklearn import svm \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report\n",
    "import aspose.words as aw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c3db6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image 'C:\\Users\\emili\\OneDrive\\Dokumente\\03_Master_CBS\\05_Summerterm24\\01_ML and DL\\Project\\png logo findder\\Original Aston Martin logo\\Image_30.png': Decompressed Data Too Large\n",
      "Error loading image 'C:\\Users\\emili\\OneDrive\\Dokumente\\03_Master_CBS\\05_Summerterm24\\01_ML and DL\\Project\\png logo findder\\Original Maserati logo\\Image_13.png': Decompressed Data Too Large\n",
      "Error loading image 'C:\\Users\\emili\\OneDrive\\Dokumente\\03_Master_CBS\\05_Summerterm24\\01_ML and DL\\Project\\png logo findder\\Original Porsche logo\\Image_18.png': Decompressed Data Too Large\n",
      "Image Dataframe: \n",
      " \n",
      "                         Label      Filename  \\\n",
      "0  Original Aston Martin logo  Image_10.png   \n",
      "1  Original Aston Martin logo  Image_11.png   \n",
      "2  Original Aston Martin logo  Image_12.png   \n",
      "3  Original Aston Martin logo  Image_13.png   \n",
      "4  Original Aston Martin logo  Image_15.png   \n",
      "\n",
      "                                               Image  \n",
      "0  <PIL.Image.Image image mode=RGB size=150x150 a...  \n",
      "1  <PIL.Image.Image image mode=RGB size=150x150 a...  \n",
      "2  <PIL.Image.Image image mode=RGB size=150x150 a...  \n",
      "3  <PIL.Image.Image image mode=RGB size=150x150 a...  \n",
      "4  <PIL.Image.Image image mode=RGB size=150x150 a...  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"Getting df with all filenames and images (missing labels at this stage) - shape = (166866,2)\"\"\"\n",
    "# only take first ten photos in each brand folder\n",
    "# (150,150) grayscale --> 2m 28.9s\n",
    "# (150,150) rgb, with pixels as cols --> \n",
    "\n",
    "def load_images_from_folder(folder_path, image_size=(150, 150)):\n",
    "    images = []\n",
    "    \n",
    "    # Recursively traverse through the folder structure\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for filename in files:\n",
    "            # Get the full path of the file\n",
    "            file_path = os.path.join(root, filename)\n",
    "            \n",
    "            # Check if the file is an image\n",
    "            if any(filename.endswith(extension) for extension in ['.jpg', '.jpeg', '.png', '.gif']):\n",
    "                # Load the image using PIL (Python Imaging Library)\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        img = img.resize(image_size) #resizing image\n",
    "                        img = img.convert('RGB') #Converting to gray scale\n",
    "                        #img_array = np.array(img) / 255.0 # Convert the image to numpy array and normalize pixel values\n",
    "                         # Extract folder name from the root path\n",
    "                        label = os.path.basename(root)\n",
    "                        \n",
    "                        images.append({'Label': label, 'Filename': filename, 'Image': img})\n",
    "                        #images.append({'Filename': filename, 'Image': img}) # Append the image array to the list\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image '{file_path}': {e}\")\n",
    "    \n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    images_df = pd.DataFrame(images)\n",
    "    return images_df\n",
    "\n",
    "# Loading\n",
    "png_folder_path=r\"C:\\Users\\emili\\OneDrive\\Dokumente\\03_Master_CBS\\05_Summerterm24\\01_ML and DL\\Project\\png logo findder\"\n",
    "image_df = load_images_from_folder(png_folder_path)\n",
    "print('Image Dataframe: \\n \\n', image_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8f21bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Image</th>\n",
       "      <th>Label coded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Original Aston Martin logo</td>\n",
       "      <td>Image_10.png</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=150x150 a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Original Aston Martin logo</td>\n",
       "      <td>Image_11.png</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=150x150 a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Original Aston Martin logo</td>\n",
       "      <td>Image_12.png</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=150x150 a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Original Aston Martin logo</td>\n",
       "      <td>Image_13.png</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=150x150 a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Original Aston Martin logo</td>\n",
       "      <td>Image_15.png</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=150x150 a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Original Porsche logo</td>\n",
       "      <td>Image_5.png</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=150x150 a...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Original Porsche logo</td>\n",
       "      <td>Image_6.png</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=150x150 a...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>Original Porsche logo</td>\n",
       "      <td>Image_7.png</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=150x150 a...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Original Porsche logo</td>\n",
       "      <td>Image_8.png</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=150x150 a...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Original Porsche logo</td>\n",
       "      <td>Image_9.png</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=150x150 a...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>369 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Label      Filename  \\\n",
       "0    Original Aston Martin logo  Image_10.png   \n",
       "1    Original Aston Martin logo  Image_11.png   \n",
       "2    Original Aston Martin logo  Image_12.png   \n",
       "3    Original Aston Martin logo  Image_13.png   \n",
       "4    Original Aston Martin logo  Image_15.png   \n",
       "..                          ...           ...   \n",
       "364       Original Porsche logo   Image_5.png   \n",
       "365       Original Porsche logo   Image_6.png   \n",
       "366       Original Porsche logo   Image_7.png   \n",
       "367       Original Porsche logo   Image_8.png   \n",
       "368       Original Porsche logo   Image_9.png   \n",
       "\n",
       "                                                 Image  Label coded  \n",
       "0    <PIL.Image.Image image mode=RGB size=150x150 a...            0  \n",
       "1    <PIL.Image.Image image mode=RGB size=150x150 a...            0  \n",
       "2    <PIL.Image.Image image mode=RGB size=150x150 a...            0  \n",
       "3    <PIL.Image.Image image mode=RGB size=150x150 a...            0  \n",
       "4    <PIL.Image.Image image mode=RGB size=150x150 a...            0  \n",
       "..                                                 ...          ...  \n",
       "364  <PIL.Image.Image image mode=RGB size=150x150 a...           13  \n",
       "365  <PIL.Image.Image image mode=RGB size=150x150 a...           13  \n",
       "366  <PIL.Image.Image image mode=RGB size=150x150 a...           13  \n",
       "367  <PIL.Image.Image image mode=RGB size=150x150 a...           13  \n",
       "368  <PIL.Image.Image image mode=RGB size=150x150 a...           13  \n",
       "\n",
       "[369 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "image_df['Label coded'] = label_encoder.fit_transform(image_df['Label'])\n",
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3f25a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split it into features and labels\n",
    "images = image_df.drop(['Filename','Label coded','Label'], axis=1)\n",
    "labels = image_df[['Label coded']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40d40790",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test, y_train, y_test=train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4d0fb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(295, 24)\n",
      "(74, 24)\n"
     ]
    }
   ],
   "source": [
    "# perform PCA on X to reduce amount of features\n",
    "# reduce to dimensionality so that 80% of variance is kept\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Convert PIL images/tensors in DataFrame to NumPy array\n",
    "X_train = np.array([np.array(img) for img in X_train.iloc[:, 0]])\n",
    "X_test = np.array([np.array(img) for img in X_test.iloc[:, 0]])\n",
    "\n",
    "# reshape features accordingly to SVM architecture NOTE: train test split again!!\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "pca = PCA(n_components=0.8, random_state=42)\n",
    "X_pca_train = pca.fit_transform(X_train)\n",
    "\n",
    "# check how many principal components are needed\n",
    "pca.n_components_\n",
    "\n",
    "# apply the trained PCA model on the test set as well\n",
    "X_pca_test = pca.transform(X_test)\n",
    "\n",
    "# check that PCA worked\n",
    "print(X_pca_train.shape)\n",
    "print(X_pca_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d55f170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the linear SVM model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', class_weight='balanced', probability=True, random_state=42)\n",
    "multi_svm = ClassifierChain(svm)\n",
    "\n",
    "# define the hyperparameter grid\n",
    "param_grid = {\n",
    "    # the selection of the hyperparameters was in the beginning larger and reduced after some tries\n",
    "    # restricting the model with smaller values made the best results\n",
    "    'base_estimator__C':[2**-5, 2**-4, 2**-3, 2**-1],\n",
    "}\n",
    "\n",
    "# define the scoring metric\n",
    "scorer = make_scorer(roc_auc_score, multi_class='ovr', average='macro')\n",
    "\n",
    "# define the grid search\n",
    "grid = GridSearchCV(\n",
    "    multi_svm,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=scorer,\n",
    "    refit=True,\n",
    "    return_train_score=True,\n",
    "    verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abfb81c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_estimator__C=0.03125;, score=(train=nan, test=nan) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_estimator__C=0.03125;, score=(train=nan, test=nan) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_estimator__C=0.03125;, score=(train=nan, test=nan) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_estimator__C=0.03125;, score=(train=nan, test=nan) total time=   0.2s\n",
      "[CV 5/5] END base_estimator__C=0.03125;, score=(train=nan, test=nan) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_estimator__C=0.0625;, score=(train=nan, test=nan) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_estimator__C=0.0625;, score=(train=nan, test=nan) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_estimator__C=0.0625;, score=(train=nan, test=nan) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_estimator__C=0.0625;, score=(train=nan, test=nan) total time=   0.2s\n",
      "[CV 5/5] END base_estimator__C=0.0625;, score=(train=nan, test=nan) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_estimator__C=0.125;, score=(train=nan, test=nan) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_estimator__C=0.125;, score=(train=nan, test=nan) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_estimator__C=0.125;, score=(train=nan, test=nan) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_estimator__C=0.125;, score=(train=nan, test=nan) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_estimator__C=0.125;, score=(train=nan, test=nan) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_estimator__C=0.5;, score=(train=nan, test=nan) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_estimator__C=0.5;, score=(train=nan, test=nan) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_estimator__C=0.5;, score=(train=nan, test=nan) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_estimator__C=0.5;, score=(train=nan, test=nan) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 620, in roc_auc_score\n",
      "    return _multiclass_roc_auc_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 693, in _multiclass_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\emili\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_estimator__C=0.5;, score=(train=nan, test=nan) total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=ClassifierChain(base_estimator=SVC(class_weight=&#x27;balanced&#x27;,\n",
       "                                                          kernel=&#x27;linear&#x27;,\n",
       "                                                          probability=True,\n",
       "                                                          random_state=42)),\n",
       "             param_grid={&#x27;base_estimator__C&#x27;: [0.03125, 0.0625, 0.125, 0.5]},\n",
       "             return_train_score=True,\n",
       "             scoring=make_scorer(roc_auc_score, multi_class=ovr, average=macro),\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=ClassifierChain(base_estimator=SVC(class_weight=&#x27;balanced&#x27;,\n",
       "                                                          kernel=&#x27;linear&#x27;,\n",
       "                                                          probability=True,\n",
       "                                                          random_state=42)),\n",
       "             param_grid={&#x27;base_estimator__C&#x27;: [0.03125, 0.0625, 0.125, 0.5]},\n",
       "             return_train_score=True,\n",
       "             scoring=make_scorer(roc_auc_score, multi_class=ovr, average=macro),\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ClassifierChain</label><div class=\"sk-toggleable__content\"><pre>ClassifierChain(base_estimator=SVC(class_weight=&#x27;balanced&#x27;, kernel=&#x27;linear&#x27;,\n",
       "                                   probability=True, random_state=42))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight=&#x27;balanced&#x27;, kernel=&#x27;linear&#x27;, probability=True, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight=&#x27;balanced&#x27;, kernel=&#x27;linear&#x27;, probability=True, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=ClassifierChain(base_estimator=SVC(class_weight='balanced',\n",
       "                                                          kernel='linear',\n",
       "                                                          probability=True,\n",
       "                                                          random_state=42)),\n",
       "             param_grid={'base_estimator__C': [0.03125, 0.0625, 0.125, 0.5]},\n",
       "             return_train_score=True,\n",
       "             scoring=make_scorer(roc_auc_score, multi_class=ovr, average=macro),\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the SVMs\n",
    "grid.fit(X_pca_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58a9856b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_estimator__C</th>\n",
       "      <th>Training Mean AUC</th>\n",
       "      <th>Validation Mean AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.03125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.12500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   base_estimator__C  Training Mean AUC  Validation Mean AUC\n",
       "0            0.03125                NaN                  NaN\n",
       "1            0.06250                NaN                  NaN\n",
       "2            0.12500                NaN                  NaN\n",
       "3            0.50000                NaN                  NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check performance of the models\n",
    "pd.concat([pd.DataFrame(grid.cv_results_[\"params\"]),pd.DataFrame(grid.cv_results_[\"mean_train_score\"], columns=[\"Training Mean AUC\"]),pd.DataFrame(grid.cv_results_[\"mean_test_score\"], columns=[\"Validation Mean AUC\"])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f5ba33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'base_estimator__C': 0.03125}\n"
     ]
    }
   ],
   "source": [
    "# print the best hyperparameters\n",
    "print('Best Hyperparameters: ', grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04da1f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the test set (probabilities)\n",
    "y_pred_prob = grid.predict_proba(X_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dc231b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multi_class must be in ('ovo', 'ovr')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# get auc from the test set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m auc_score \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, y_pred_prob, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:619\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial AUC computation not available in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass setting, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_fpr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    615\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m set to `None`, received `max_fpr=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    616\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(max_fpr)\n\u001b[0;32m    617\u001b[0m         )\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multi_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_class must be in (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _multiclass_roc_auc_score(\n\u001b[0;32m    621\u001b[0m         y_true, y_score, labels, multi_class, average, sample_weight\n\u001b[0;32m    622\u001b[0m     )\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: multi_class must be in ('ovo', 'ovr')"
     ]
    }
   ],
   "source": [
    "# get auc from the test set\n",
    "auc_score = roc_auc_score(y_test, y_pred_prob, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee9caa42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07],\n",
       "       [0.1 ],\n",
       "       [0.07],\n",
       "       [0.05],\n",
       "       [0.07]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check predictions (probabilities)\n",
    "y_pred_prob[:5].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7e6c63d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 67500 features, but ClassifierChain is expecting 24 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# make predictions on the test set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:519\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \n\u001b[0;32m    503\u001b[0m \u001b[38;5;124;03mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;124;03m    the best found parameters.\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    518\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 519\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:758\u001b[0m, in \u001b[0;36m_BaseChain.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict on the data matrix X using the ClassifierChain model.\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \n\u001b[0;32m    747\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;124;03m    The predicted values.\u001b[39;00m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    757\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 758\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    759\u001b[0m Y_pred_chain \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_)))\n\u001b[0;32m    760\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chain_idx, estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 67500 features, but ClassifierChain is expecting 24 features as input."
     ]
    }
   ],
   "source": [
    "# make predictions on the test set\n",
    "y_pred = grid.predict(X_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb800706",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# check predictions \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred[:\u001b[38;5;241m5\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# check predictions \n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8247bf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multi_class must be in ('ovo', 'ovr')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# get auc from the test set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m auc_score \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, y_pred_prob, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:619\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial AUC computation not available in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass setting, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_fpr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    615\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m set to `None`, received `max_fpr=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    616\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(max_fpr)\n\u001b[0;32m    617\u001b[0m         )\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multi_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_class must be in (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _multiclass_roc_auc_score(\n\u001b[0;32m    621\u001b[0m         y_true, y_score, labels, multi_class, average, sample_weight\n\u001b[0;32m    622\u001b[0m     )\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: multi_class must be in ('ovo', 'ovr')"
     ]
    }
   ],
   "source": [
    "# get auc from the test set\n",
    "auc_score = roc_auc_score(y_test, y_pred_prob, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e219b61e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12a40aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\EmiliaGachowetz-Gepp\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5f2065d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\EmiliaGachowetz-Gepp\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\EmiliaGachowetz-Gepp\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 225, 225, 128)     3584      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 225, 225, 128)     147584    \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 225, 225, 128)     512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 225, 225, 256)     295168    \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 112, 112, 256)     0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 112, 112, 256)     590080    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 112, 112, 256)     1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 56, 56, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 56, 56, 256)       1638656   \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 28, 28, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 200704)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               102760960 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 27)                6939      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107346075 (409.49 MB)\n",
      "Trainable params: 107345307 (409.49 MB)\n",
      "Non-trainable params: 768 (3.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2=keras.models.Sequential([\n",
    "    #keras.layers.Flatten(input_shape=(227,227,3)),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', input_shape=(227,227,3)),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding=\"same\"),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding=\"same\"),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding=\"same\"),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding=\"same\"),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), activation='relu', padding=\"same\"),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512,activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(256,activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(27,activation='softmax') \n",
    "])\n",
    "    \n",
    "    \n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cb8d7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\EmiliaGachowetz-Gepp\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb98c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-Load the dataset\n",
    "loaded_data = np.load(\"my_dataset_aug_full.npz\", allow_pickle=True)\n",
    "\n",
    "# Access images and labels\n",
    "loaded_images = loaded_data['images']\n",
    "\n",
    "# Now you can use loaded_images and loaded_labels in your code\n",
    "image_df=pd.DataFrame(loaded_images)\n",
    "\n",
    "#split it into features and labels\n",
    "features = image_df.iloc[:, :51529]\n",
    "labels = image_df.iloc[:, 51530]\n",
    "labels_coded=image_df.iloc[:,51531]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a69f63b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (7925, 51529)\n",
      "X_test shape: (1982, 51529)\n",
      "y_train shape: (7925,)\n",
      "y_test shape: (1982,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels_coded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting splits\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eb9422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try-outs with smaller subsets:\n",
    "X_train_subset = X_train[:100]\n",
    "y_train_subset = y_train[:100]\n",
    "X_test_subset = X_test[:100]\n",
    "y_test_subset = y_test[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "610b6b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subset=X_train_subset/255.0\n",
    "X_test_subset=X_test_subset/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a75600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_pic = X_train_subset.iloc[0]\n",
    "one_pic_array = one_pic.values.astype(float)  # Convert to float\n",
    "one_pic_image = one_pic_array.reshape((227, 227))\n",
    "one_pic_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5857fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 227, 227)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def image_reshape(image_df):\n",
    "    images = []\n",
    "    for idx, row in image_df.iterrows():\n",
    "        one_pic_array = row.values.astype(float)\n",
    "        one_pic_image = one_pic_array.reshape((227, 227))\n",
    "        images.append(one_pic_image)\n",
    "    return np.array(images)\n",
    "\n",
    "reshaped_images = image_reshape(X_train_subset)\n",
    "reshaped_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ce3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "reshaped_images_tensor = torch.tensor(reshaped_images, dtype=torch.float32)\n",
    "y_train_subset=np.array(y_train_subset, dtype=np.float32)\n",
    "reshaped_labels_tensor = torch.tensor(y_train_subset, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a87cef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reshaped = np.array(reshaped_images, dtype=np.float32)\n",
    "y_train_subset=np.array(y_train_subset, dtype=np.float32)\n",
    "\n",
    "# Reshape the input images to include the channel dimension\n",
    "reshaped_images_array = np.expand_dims(X_train_reshaped, axis=-1)\n",
    "reshaped_images_array = np.tile(reshaped_images_array, (1, 1, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeee3e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 227, 227, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_images_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21792c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EmiliaGachowetz-Gepp\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\EmiliaGachowetz-Gepp\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\EmiliaGachowetz-Gepp\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_2.fit(reshaped_images_array, y_train_subset, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750954b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_images_test = image_reshape(X_test_subset)\n",
    "X_test_reshaped = np.array(reshaped_images_test, dtype=np.float32)\n",
    "y_test_subset=np.array(y_test_subset, dtype=np.float32)\n",
    "\n",
    "# Reshape the input images to include the channel dimension\n",
    "X_test_reshaped = np.expand_dims(X_test_reshaped, axis=-1)\n",
    "X_test_reshaped = np.tile(reshaped_images_array, (1, 1, 1, 3))\n",
    "\n",
    "test_loss, test_acc = model_2.evaluate(X_test_reshaped,  y_test_subset, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b3568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "probability_model = tf.keras.Sequential([model_2, \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "\n",
    "predictions = probability_model.predict(X_test_reshaped)\n",
    "print(predictions[0])\n",
    "#A prediction is an array of 10 numbers. They represent the model's \"confidence\" that the image corresponds to each of the 27 different logos.\n",
    "#You can see which label has the highest confidence value by calling:\n",
    "print(f'most probable logo is',np.argmax(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588c85fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model is most confident that this image is of class XX\n",
    "#Examining the test label shows that this classification is correct?False?:\n",
    "\n",
    "y_test_subset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
